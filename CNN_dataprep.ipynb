{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and merging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame()\n",
    "# for file in glob(\"shifts_123_valid/*.csv\"):\n",
    "#     shift_df = pd.read_csv(file)\n",
    "#     col = [\"timeleft\", \"shift\",\"tostop\", \"train_test\",\"stoplon\", \"stoplat\", \"Lon\", \"Lat\", 'Timestamp', \"speed_smooth_10\", \"timepast\", \"delay\", \"deltalon\", \"deltalat\",\"tostop_estimate\",\"time_avg\"]\n",
    "#     shift_df = shift_df[col]\n",
    "#     shift_df['Timestamp'] = pd.to_datetime(shift_df['Timestamp'])\n",
    "#     shift_df[\"hour\"] = shift_df[\"Timestamp\"].apply(lambda x: x.hour)\n",
    "#     shift_df[\"weekday\"] = shift_df[\"Timestamp\"].apply(lambda x: x.weekday())\n",
    "#     df = pd.concat([df, shift_df],ignore_index=True)\n",
    "\n",
    "    \n",
    "# with open('data/shifts_new_123.pickle', 'wb') as handle:\n",
    "#     pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/shifts_new_123.pickle', 'rb') as handle:\n",
    "    df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_columns = df.columns[df.isnull().any()].tolist()\n",
    "df = df.dropna(subset=missing_columns,how='any')\n",
    "df = df.dropna(how='any') \n",
    "df[\"tostop_estimate\"] = df[\"tostop_estimate\"] - df[\"time_avg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating faeture matrix for CNN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuanmh/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/yuanmh/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "shifts_list = df[\"shift\"].unique().tolist()\n",
    "stops_list = df[\"tostop\"].unique().tolist()\n",
    "start = time.time()\n",
    "count = 0\n",
    "for shift in shifts_list[:]:\n",
    "    sub_df = df[df[\"shift\"]==shift]\n",
    "\n",
    "    df_out = pd.DataFrame()\n",
    "    for stop in stops_list:\n",
    "        sub_sub_df = sub_df[sub_df[\"tostop\"] == stop]\n",
    "        try:\n",
    "            test = sub_sub_df[\"train_test\"].tolist()[0]\n",
    "        except:\n",
    "            continue\n",
    "        sub_sub_df[\"deltalon\"] = sub_sub_df[\"stoplon\"] - sub_sub_df[\"Lon\"]\n",
    "        sub_sub_df[\"deltalat\"] = sub_sub_df[\"stoplat\"] - sub_sub_df[\"Lat\"]\n",
    "        sub_sub_df = sub_sub_df.reset_index().drop(\"index\", axis = 1)\n",
    "\n",
    "        cache_df = pd.DataFrame()\n",
    "        for index, row in sub_sub_df.iterrows():\n",
    "            if index % 10 == 0:\n",
    "                cur_row = row[[\"Lon\", \"Lat\", \"hour\", \"weekday\", \"speed_smooth_10\", \"timepast\", \"delay\", \"deltalon\", \"deltalat\",\"tostop_estimate\"]]\n",
    "                cur_row = pd.DataFrame(np.array(cur_row).reshape(1,10))\n",
    "                \n",
    "                cache_df = pd.concat([cache_df, cur_row] , ignore_index=True)               \n",
    "                if cache_df.shape[0] == 10:\n",
    "                    df_out = pd.concat([df_out, pd.DataFrame(np.append(cache_df.as_matrix().reshape((1,100)), row[\"timeleft\"]).reshape((1,101)))] , ignore_index=True)\n",
    "                    cache_df = cache_df.loc[1:,]\n",
    "\n",
    "    if test:\n",
    "        df_out.to_csv(\"cnndata_123/\"+str(shift)+\"_test.csv\", index=False, header = False)\n",
    "    else:\n",
    "        df_out.to_csv(\"cnndata_123/\"+str(shift)+\"_train.csv\", index=False, header = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
